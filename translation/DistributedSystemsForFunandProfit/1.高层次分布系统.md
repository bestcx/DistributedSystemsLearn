# 分布式系统一

## 高层次的分布式系统

> 分布式系统是解决同一问题的艺术，你可以用多台计算机解决在一台计算机上同样的问题

任何计算机都需要完成俩个基础任务:

- 存储
- 计算

​       不是所有的问题都需要你使用分布式系统来解决. 如果我们拥有足够的(infinite)钱和足够的研发(R&D)时间,我们是不需要分布式系统的. 这样就意味着你需要花费大量的人力去设计一个难以置信(incredibly) 的快和可用的系统在一台计算机上进行计算和存储.

​		然而,在现实中,我们很难拥有这些足够的资源. 因此,我们不得不从其他方面来替代. 在一个小规模(scale)的计算和存储下, 提升(upgrading)硬件是一个可用的策略(strategy). 然而当问题规模不断增大, 此时你所期望的目标已经无法在单台机器上通过提升硬件来达成或者这其中的花费已经溢价.在这种情况下我们期望有分布式系统.

​		目前的现实是，最具价值的是中档商用(commodity)硬件,我们只要通过容错软件就能够降低维护成本。

​		计算其实主要受益于高端的硬件, 在某种程度下(to the extent to), 他们可以通过内部的内存访问来代替缓慢的网络访问. 高端硬件的性能(performance)将受限于需要大量节点进行通信的任务(计算节点和数据节点不一致,需要对数据或者是计算进行网络的传输)

![cost-efficiency](http://book.mixu.net/distsys/images/barroso_holzle.png)

​		在[Barroso, Clidaras & Hölzle](http://www.morganclaypool.com/doi/abs/10.2200/S00516ED2V01Y201306CAC024) 的论文中的图形就指出了, 假设在所有的节点上都采用统一的内存访问模式,在高端硬件和商用硬件的性能差距会随着集群规模的增大而减小.

> 笔记
>
> ​		内存访问模式: 
>
> ​		

​        在理想情况下,	添加一台新的机器会线性地(linearly)增加系统的性能和容量. 但这当然是不可能的,因为当有独立的多台计算势必会出现(arises)一些其他开销(overhead). 数据需要复制到其他服务器上,计算也得进行协调等等. 这也是为什么分布式算法是我们值得去学习的 - 他可以提供有效的解决方案去处理特定的问题.以及指导我们什么是能做到的,什么是不能做到的和实现一个正确需求的最小花费是什么.	

​		本文关注的重点是日常的分布式程序和系统, 但是与商业相关的是数据中心. 例如, 我不会讨论由于外来(exotic)的网络配置,或者是共享内存而引发的特定问题. 此外,我们探索的重点是系统空间设计而不是去优化(optimizing)特定的设计.后者是一个更加特殊的主题.

## 目标: 可扩展能力和其他



​		在我看来,一切都始于对规模的需求.

​		很多东西在一个小的规模下是不重要的 - 当你超过一定的大小,容器卷,或者其他的物理约束,相同的问题可能会变得更难.举起一块巧克力很容易，举起一座山却很难。要数出一个房间里有多少人很容易，但要数出一个国家有多少人就很难了。

​		因此,所有都起始于规模,也就是扩展能力. 简单来说(Informally speaking), 当我们从小规模迁移到大规模上,对于可扩展的系统, 事情不会变得很差.

>  [Scalability](http://en.wikipedia.org/wiki/Scalability)	
>
> 可扩展性是指系统,网络,进程使用一种有效的(capable)处理方式去处理不断增加的工作量的能力,或者说是适应(accommodate)这种增长而不断扩展的能力.

​	

​		什么是增长性. 你几乎可以使用任何方式来测量增长(人口的数量,电量使用的度数),但有三件事特别有趣:

- 规模可扩展:  增加更多的节点时,系统的响应速度应该线性增长.	不断增加的数据量不会增加延迟
- 空间可扩展:  应该使用多个数据中心来减少用户查询的响应时间,同时以合理的(sensible)方式处理跨数据中心的延迟.
- 管理可扩展:  增加节点时不应该增大管理(Administrative)的成本



​		当然在真实系统中, 这些增长同时(simultaneously)发生在不同的方面, 每个指标只能反映增长了某些方面.

​		一个可扩展的系统会随着集群规模的不断增大能满足用户需求的系统. 这有俩个格外(particularly)需要注意的方面.可用性和延迟,因为他们可以通过各种各样的方式来进行测量.

## 性能和延迟

> [Performance](http://en.wikipedia.org/wiki/Computer_performance)
>
> 性能就是计算机完成有用工作量与花费的时间和资源的比例的一种表现.

​		根据其定义,  他包含以下一个或多个目标:

- 低响应/给定工作的延迟
- 高吞吐量(throughput)(处理工作速度)
- 低资源利用率




​		在优化这些结果的过程中我们都需要进行权衡(tradeoffs). 例如一个系统需要执行很多次批作业来实现高吞吐, 从而减少操作上的开销. 因为进行批处理,单个工作的响应时间会因为中间的权衡变的更长.

​		我认为, 低延迟(实现响应时间短) 是性能方面最有趣的地方. 因为他和物理限制有很强的联系而不是金钱.	因此与性能的其他方面相比,使用金钱去解决延迟方面的问题会更难.

​		有许多对延迟的定义.

>  **Latency**			
>
> 从初始化到发生的一段时间
>
> **Latent**	
>
> 他是存在或者是有但是是隐藏起来的不活动的

​		这个定义非常不错,  因为他强调(highlights)了延迟就是指从事件发生到他产生影响或者是变得可见的这段时间.

​		例如，假设你感染了一种通过空气传播的病毒，它能把人变成僵尸。延迟是指你被感染到变成僵尸之间的时间。这就是延迟: 已经发生的事情被隐藏起来的时间。

​		我们暂时先做一个假设: 使用分布式系统去做一个高级的任务, 做一个查询, 将系统里所有的数据查出来,并且计算出一个结果. 换句话说,我们可以吧分布式系统想象成一个具有其他能力的数据存储,这个能力就是根据他的内容可以执行一个确定的计算或函数. `result = query(all data in the system)`

​		影响延迟的并不是旧数据的数量而是新数据在系统中产生效应的数据. 我们可以根据写数据的操作到数据可读的时间来衡量延迟.

​		在这个定义下,还有一些其他关键的点, 如果在这个时间点什么都没有发生, 就是没有延迟. 在系统中数据没有发生改变就不会有延迟.

​		在分布式系统中, 有一个最小延迟时候不可避免的,光速限制了信息的传播速度，每个操作都会在硬件上都会产生小的延迟(想想RAM和硬盘驱动器，还有cpu)。

​		这个最小延迟对查询的影响程度取决于这些查询的性质和信息需要传输的物理距离。

## 可用性和错误容忍

> **[Availability](http://en.wikipedia.org/wiki/High_availability)**
>
> 系统处于处于运行状态的时间比例. 当用户无法访问系统, 就说是这个系统不可用
>
> ​	

​		分布式系统允许我们实现在单个系统难以实现的理想特性. 例如,单机是不能容忍(tolerate)任何错误.因为他要么成功,要么失败.	

​		分布式系统可以依靠一堆不可靠的组件,并在他们上面构建一个可靠的系统.

​		没有冗余的系统仅仅能实现与底层组件一样的可用性. 系统进行冗余(redundancy)构建,就可以容忍部分的错误并且因此变得更可用. 值得注意的是(It is worth noting that),冗余意味着不同的东西,这取决于你要做的是什么-- 组件,服务器,数据中心等等.

> uptime 正常运行时间
>
> downtime 故障时间

​		从公式上来看` Availability = uptime / (uptime + downtime)`

​		可用性从技术上来说就是能实现错误容忍. 在许多组件下错误发生的概率也会增加, 因此系统应该能够进行补偿(compensate), 以免(so as to)随着组件规模的增大系统可用性减少.

For example:

| Availability %         | How much downtime is allowed per year? |
| ---------------------- | -------------------------------------- |
| 90% ("one nine")       | More than a month                      |
| 99% ("two nines")      | Less than 4 days                       |
| 99.9% ("three nines")  | Less than 9 hours                      |
| 99.99% ("four nines")  | Less than an hour                      |
| 99.999% ("five nines") | ~ 5 minutes                            |
| 99.9999% ("six nines") | ~ 31 seconds                           |

​		在某些观念下, 可用性这个概念要比正常运行时间这个概念更宽泛. 因为服务的可用性可能会受到这些的影响,像网络的中断,服务公司的停业(这些都是与错误容忍无关的因素,但是他确确实实会影响到服务的可用性). 但是在不了解系统的每个具体方面的情况下，我们能做的最好的就是设计容错。



> **Fault tolerance**
>
> 容错就是当系统发生错误后系统还能够按照正常的方式进行运行.

​		容错可以归结为(boils down to this): 	你可以自己设计一个系统或者是一个算法来容忍你能预料到系统可能发生的错误. 你不能容忍你没有考虑到的错误发生.

## 什么妨碍了一个好的系统出现

​		分布式系统被俩个物理因素所约束

		- 节点的数量 (随着内存需要和计算容量增加而增加)
		- 节点间的距离(信息最快以光速传播)

​		 我们将在这些约束下进行工作

			- 当所依赖的节点数量增大时错误出现的概率也会增大(他会降低可用性和增加管理成本)
   - 当所依赖的节点数量增大时节点间的通讯也会增加(他会降低大规模集群的性能)
   - 当节点间的距离增加, 因为通讯就会增加最低延迟(他会降低操作的性能)



​			在这些趋势下, 系统设计的选择是物理约束的结果.

​			性能和可用性是由系统做出的外部保证来定义的. 在高层次下,你可以将这种保证视为系统的SLA(服务等级协议): 当我写了一个数据,我可以在任何地方最快访问到他. 当数据成功写入, 数据的持久性怎么来保证. 当我使用系统执行一次计算,他多快可以给我返回结果. 当组件挂了,或者是操作超时了,这将对系统产生什么影响.

​		还有另外一个标准,虽然没有明确(explicitly)提起,但是在这其中也隐含着: 可理解性. 这些保证的易理解性, 但是没有什么指标能衡量他.

​		我有点想把可理解性置于物理限制之下, 毕竟他是一个对于人来说的一个物理限制,我们其实很难去理解没有通过我们的操作而发生的事. 这里还有点区别在错误和异常上, 错误是一个不正确的行为,而异常是一个没有预料到的行为. 如果我们足够聪明,我们其实可以预料到异常的发生.

## 抽象和模型

​		这就是抽象和模型发挥作用的地方。抽象是通过删除与解决问题无关的实际方面,让事情变得更易于管理.模型精确的描述了分布式系统的关键属性. 接下来的几章也会讲述几个模型

- 系统模型(异步/同步)
- 错误解决模型(停机故障,分区,拜占庭)
- 一致性模型(强一致性,最终一致性)

​        一个好的抽象会将系统的工作变得更简单,更容易理解.同时捕获到与特定目标相关的因素.

​		在我们的系统拥有许多的节点和我们希望系统能够像单个节点一样工作之间存在一种张力(tension). 最接近的一种的模型比如实现共享内存抽象的代价非常昂贵.

​		一个提供弱保证的系统会拥有更自由的操作并且能发挥出更大的能力, 但是很难去找出问题出现的原因.我们更擅长去找出单个系统出现的问题,而不是有一堆节点的系统.

​		人们通常可以通过系统内部里的一些细节来提升性能. 例如, 在列式存储下,用户在某种程序下可以推断出k-v键值对在系统中的位置,并且根据这些做出影响查询性能的决策.隐藏这些细节的系统更容易理解(因为它们更像一个单元，需要考虑的细节更少)，而暴露更多现实细节的系统可能更出色(因为它们更贴近现实)。

​		几种错误的类型会让编写分布式系统比单个系统更难.网络延迟和网络分裂(例如,节点间的网络总故障)就意味着系统有时需要做出艰难的选择:是保持可用性但失去一些不能强制执行的关键保证更好，还是在这些类型的故障发生时保持安全并拒绝客户端。

> **Network Partition**
>
> 即网络分裂。一种在系统的任何两个组之间的所有网络连接同时发生故障后所出现的情况。发生这种情况时，分裂的系统双方都会从对方一侧重新启动应用程序，进而导致重复服务或裂脑。如果一个群集中配置的两个独立系统具有对指定资源（通常是文件系统或卷）的独占访问权限，则会发生裂脑情况。由网络分裂造成的最为严重的问题是它会影响共享磁盘上的数据。

​		CAP理论在下一章进行讲述.最终，理想的系统能够同时满足程序员的需求(清晰的语义(semantics))和业务需求(可用性/一致性/延迟)。

## 设计上的技术: 分区和副本

​		数据集在多个节点上进行传送的行为是非常重要的. 为了让所有的计算都能够发生,我们需要把数据定位出来,并且投入计算.

​		有俩个很基础的技术可以作用到数据集上.  分区: 将数据切分到不同的节点上用于并行计算. 副本:  可以将数据缓冲或者拷贝到不同的节点来缩短客户端和服务端的距离,并且能更好的支持错误容忍. 

​		下面的图说明这俩者的区别: 

​		分区是将数据分割到独立的数据集上,而副本是将数据拷贝到不同的node上.

![Partition and replicate](http://book.mixu.net/distsys/images/part-repl.png)

​		这是所有分布式计算来解决问题的一套通用手段.当然，诀窍(trick)在于为具体实现选择正确的技术;有许多实现复制和分区的算法，每一种算法都有不同的限制和优点，需要根据您的设计目标进行评估。

### 分区

​		分区是将数据集切分到不同的小的独立的集合上. 因为每个分区都是数据的子集,所有他一般就用来减少不断增大的数据集的影响. 

- 分区通过限制要检查的数据量和定位在同一分区的数据来提升性能
- 分区通过允许分区独立发生故障来提高可用性，从而增加了在牺牲(sacrificed)可用性之前需要发生故障的节点数量。

>  数据被分割到不同的节点上, 节点同时发生故障的概率低, 分区数据的可用性会增大

​		分区的具体实现是基于特定应用的,如果不知道这些细节我们是很难去描述. 这也是我们在文章中更多的关注副本,包括本篇内容.

​		分区更多的定义是通过你怎么考虑主进程的匹配规则,并且怎么处理数据到独立的分区的限制.

### 副本

​		副本是拷贝相同的数据到不同的机器上. 这样可以使更多的机器参与到运算上面.

​		副本, 拷贝或者复制(reproducing)数据, 这是我们主要对抗的延迟的方法.

		- 副本提升性能通过增加额外的计算资源和带宽去应用到新复制出来的数据上.

- 副本提升可用性通过增加额外复制出来的数据,增加大量的可能会失效的节点.

​       副本在计算时提供额外的带宽和缓存,但是这也意味着我们需要使用一致性的模型来保证一致性(maintaining).

​		副本机制允许我们实现可扩展性.性能和错误容忍的目标. 害怕失去可用性或者是降低性能. 备份数据来避免瓶颈(bottleneck)或者单点故障. 计算太慢? 备份计算到不同的机器上. I/O太慢? 备份数据到本地缓存来减少延迟,或者备份到不同的机器上来增加吞吐.

​		副本机制同时会带来很多的问题. 因为这些独立的一块一块的数据必须在不同的机器上要保持同步,这也意味着必须要使用一致性的模型来确保数据是一致的.

​		一致性模型的选择是非常重要的, 一个好的模型会提供清晰的程序语法(简而言之, 他保证我们可以很简单的去实现他), 同时他也能满足商用的目标像高可用和强一致性.

​		这种模型我们使用时只能选择一种:强一致性, 允许我们编写程序好像底层的数据并没有进行复制. 其他的一致性模型会暴露许多副本机制内部的东西给我们. 然而,弱一致性能提供低延迟和高可用,这些并不是很难去理解,仅仅是有些不同.

## 扩展阅读

- [The Datacenter as a Computer - An Introduction to the Design of Warehouse-Scale Machines](http://www.morganclaypool.com/doi/pdf/10.2200/s00193ed1v01y200905cac006) - Barroso & Hölzle, 2008
- [Fallacies of Distributed Computing](http://en.wikipedia.org/wiki/Fallacies_of_Distributed_Computing)
- [Notes on Distributed Systems for Young Bloods](http://www.somethingsimilar.com/2013/01/14/notes-on-distributed-systems-for-young-bloods/) - Hodges, 2013

